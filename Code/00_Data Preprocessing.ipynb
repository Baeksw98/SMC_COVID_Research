{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# COVID Severity Prediction using AI Solution - Data Preprocessing\n",
    "* By Sangwon Baek\n",
    "* Samsung Medical Center\n",
    "* March 10th, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import necessary packages and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"../Data/Original/2020_1st_COVID.xlsx\"\n",
    "path2 = \"../Data/Original/2021_2nd_COVID.xlsx\"\n",
    "path3 = \"../Data/Original/2022_3rd_COVID.xlsx\"\n",
    "path4 = \"../Data/Original/2022_3rd_2_COVID.xlsx\"\n",
    "df1 = pd.read_excel(path1, header=2)\n",
    "df2 = pd.read_excel(path2, header=2)\n",
    "df3 = pd.read_excel(path3, header=2)\n",
    "df4 = pd.read_excel(path4, header=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['diagnosis', 'No', 'ID', 'age', 'sex', 'symptom_date', 'dx_date', 'adm_date', 'hospitalized_date', 'smoking',\n",
    "        'UD_HT', 'UD_DM', 'UD_CVD', 'UD_cancer', 'UD_other','SMT_fever', 'SMT_cough', 'SMT_sputum', 'SMT_dyspnea', \n",
    "        'SMT_myalgia', 'SMT_sorethroat', 'SMT_mental', 'SMT_GI',\n",
    "\n",
    "        'Initial_BT', 'Initial_SBP', 'Initial_DBP', 'Initial_PR', 'Initial_RR', 'Initial_SPO2', 'Initial_FIO2',\n",
    "        'Initial_CXR', 'Initial_CT', 'Initial_WBC', 'Initial_ANC', 'Initial_ALC', 'Initial_PLT', 'Initial_CRP', \n",
    "        'Initial_LDH', 'Initial_DD', 'Initial_PCR_c', 'Initial_PCR_r',\n",
    "\n",
    "        'FU1_BT', 'FU1_SBP', 'FU1_DBP', 'FU1_PR', 'FU1_RR', 'FU1_SPO2', 'FU1_FIO2', 'FU1_CXR', 'FU1_CT', \n",
    "        'FU1_WBC', 'FU1_ANC', 'FU1_ALC', 'FU1_PLT', 'FU1_CRP', 'FU1_LDH', 'FU1_DD', 'FU1_PCR_c', 'FU1_PCR_r',\n",
    "\n",
    "        'FU2_BT', 'FU2_SBP', 'FU2_DBP', 'FU2_PR', 'FU2_RR', 'FU2_SPO2', 'FU2_FIO2','FU2_CXR', 'FU2_CT',\n",
    "        'FU2_WBC', 'FU2_ANC', 'FU2_ALC', 'FU2_PLT', 'FU2_CRP', 'FU2_LDH', 'FU2_DD', 'FU2_PCR_c', 'FU2_PCR_r',    \n",
    "\n",
    "        'FU3_BT', 'FU3_SBP', 'FU3_DBP', 'FU3_PR', 'FU3_RR', 'FU3_SPO2', 'FU3_FIO2', 'FU3_CXR', 'FU3_CT',\n",
    "        'FU3_WBC', 'FU3_ANC', 'FU3_ALC', 'FU3_PLT', 'FU3_CRP', 'FU3_LDH', 'FU3_DD', 'FU3_PCR_c', 'FU3_PCR_r',    \n",
    "\n",
    "        'FU4_BT', 'FU4_SBP', 'FU4_DBP', 'FU4_PR', 'FU4_RR', 'FU4_SPO2', 'FU4_FIO2', 'FU4_CXR', 'FU4_CT',\n",
    "        'FU4_WBC', 'FU4_ANC', 'FU4_ALC', 'FU4_PLT', 'FU4_CRP', 'FU4_LDH', 'FU4_DD', 'FU4_PCR_c', 'FU4_PCR_r',    \n",
    "\n",
    "        'Last_BT', 'Last_SBP', 'Last_DBP', 'Last_PR', 'Last_RR', 'Last_SPO2', 'Last_FIO2', 'Last_CXR', 'Last_CT',\n",
    "        'Last_WBC', 'Last_ANC', 'Last_ALC', 'Last_PLT', 'Last_CRP', 'Last_LDH', 'Last_DD', 'Last_PCR_c', 'Last_PCR_r',    \n",
    "\n",
    "        'TX', 'steroid', 'O2sup', 'ventilator', 'ECMO', 'ICU_date', 'Mortality', 'discharge_date']\n",
    "for cnt, i in enumerate(df1.columns):\n",
    "    df1.rename(columns={i:columns[cnt]}, inplace=True)\n",
    "for cnt2, j in enumerate(df2.columns):\n",
    "    df2.rename(columns={j:columns[cnt2]}, inplace=True)\n",
    "for cnt3, k in enumerate(df3.columns):\n",
    "    df3.rename(columns={k:columns[cnt3]}, inplace=True)\n",
    "for cnt4, k in enumerate(df4.columns):\n",
    "    df4.rename(columns={k:columns[cnt4]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conduct necessary preprocessing implementation for new dataframe\n",
    "df4['FU2_DBP'] = df4['FU2_DBP'].replace(\" \", np.nan)\n",
    "df4['Initial_CRP'] = pd.to_numeric(df4['Initial_CRP'], errors='coerce')\n",
    "df4['FU2_DBP'] = pd.to_numeric(df4['FU2_DBP'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [df1, df2, df3, df4]\n",
    "#Merge the three datasets to create dataframe\n",
    "df = pd.concat(temp)    \n",
    "#Reset index for dataset\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9199"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    5470\n",
       "0    2476\n",
       "2     665\n",
       "1     588\n",
       "Name: smoking, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.smoking.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ nan   6.   7.   8.   3.  10.   0.   1.   5.   9.   2.   4.  16.  21.\n",
      "  13.  -1.  25.  30.  53.  17.  14.  46.  12.  18. -12.  19.  11.  26.\n",
      "  50.  -2.  38.  -3.  -5.  20.  33.  42.  29.  32.  -6. 164. -11. -50.\n",
      "  41.  -8.  37. 130.  28.] ventilator\n",
      "[nan 6 10 3 1 13 'Positive' 5 16 18 7 2 30 14 8 12 17 19 4 9 81 26 15 21\n",
      " 31 107 20.0 46.0 42.0 0.0 23.0 11.0 -11.0 130.0 58.0] ECMO\n",
      "[nan 4 6 3 1 'Positive' 8 13 0 24 11.0 58.0 5.0 18.0 2.0 7.0 20.0 19.0\n",
      " 47.0 21.0 12.0 -1.0 9.0 10.0 15.0 38.0 39.0 26.0 50.0 -2.0 31.0 29.0 -4.0\n",
      " 36.0 35.0 16.0 -5.0 42.0 57.0 22.0 32.0 -13.0 25.0 28.0 -27.0 -7.0 45.0\n",
      " -3.0 -9.0 30.0 41.0 17.0 37.0 -10.0 -29.0 149.0] ICU_date\n",
      "[ 0.  1. nan] Mortality\n",
      "[nan 3.0 6.0 5.0 10.0 2.0 0.0 1.0 7.0 4.0 8.0 12.0 11.0 14.0 9.0 -1.0 -4.0\n",
      " -6.0 19.0 15.0 34.0 41.0 60.0 47.0 13.0 -8.0 36.0 24.0 17.0 16.0 87.0\n",
      " 30.0 26 -11 -31 -2 38 -3 28 -15 -5 43 'Positive' -7 -16 42 -9 49 31 -12\n",
      " 39 -21 45.0 56.0 102.0 21 103 159 32 -19 -71 -10 20 ' ' 130] O2sup\n",
      "O2 supply not null counts: 3406\n",
      "Ventilator not null counts: 724\n",
      "ECMO not null counts: 127\n",
      "ICU admission not null counts: 946\n",
      "Mortality not null counts: 8643\n"
     ]
    }
   ],
   "source": [
    "#Inspection for dependent variables\n",
    "dependentVariables = ['ventilator', 'ECMO', 'ICU_date', 'Mortality', 'O2sup']\n",
    "for item in dependentVariables:\n",
    "    print(pd.unique(df[item]), item)\n",
    "print(\"O2 supply not null counts: {}\".format(df['O2sup'].notnull().sum()))\n",
    "print(\"Ventilator not null counts: {}\".format(df['ventilator'].notnull().sum()))\n",
    "print(\"ECMO not null counts: {}\".format(df['ECMO'].notnull().sum()))\n",
    "print(\"ICU admission not null counts: {}\".format(df['ICU_date'].notnull().sum()))\n",
    "print(\"Mortality not null counts: {}\".format(df['Mortality'].notnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add mild, moderate, severe column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Mild, Moderate, Severe Column (multi-class classification)\n",
    "df['Mild'] = '0'\n",
    "df['Moderate'] = '0'\n",
    "df['Severe'] = '0'\n",
    "\n",
    "#Check for FiO2 in each period + Ventilator\n",
    "Initial_FIO2_c = df['Initial_FIO2'].notnull()\n",
    "FU1_FIO2_c = df['FU1_FIO2'].notnull()\n",
    "FU2_FIO2_c = df['FU2_FIO2'].notnull()\n",
    "FU3_FIO2_c = df['FU3_FIO2'].notnull()\n",
    "FU4_FIO2_c = df['FU4_FIO2'].notnull()\n",
    "Last_FIO2_c = df['Last_FIO2'].notnull()\n",
    "O2sup_c = df['O2sup'].notnull()\n",
    "\n",
    "#Check for dependent variables ECMO, ICU, Mortality, ventilator\n",
    "ECMO_c = df['ECMO'].notnull()\n",
    "ICU_c = df['ICU_date'].notnull()\n",
    "Mortality_c = df['Mortality'] == 1\n",
    "Ventilator_c = df['ventilator'].notnull()\n",
    "\n",
    "#Create severe column if any of dependent variables above are true\n",
    "df.loc[ECMO_c | ICU_c | Mortality_c | Ventilator_c, 'Severe'] = '1'\n",
    "Severe_c = df['Severe']=='1'\n",
    "\n",
    "#Create moderate column if any of this is true.\n",
    "df.loc[Severe_c|Initial_FIO2_c|FU1_FIO2_c|FU2_FIO2_c|FU3_FIO2_c|FU4_FIO2_c|Last_FIO2_c|O2sup_c,'Moderate'] = '1'\n",
    "\n",
    "#Create mild column if not in Moderate column\n",
    "df.loc[df['Moderate']=='0', 'Mild'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5454\n",
      "0    3745\n",
      "Name: Mild, dtype: int64\n",
      "0    5454\n",
      "1    3745\n",
      "Name: Moderate, dtype: int64\n",
      "0    7835\n",
      "1    1364\n",
      "Name: Severe, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Mild'].value_counts())\n",
    "print(df['Moderate'].value_counts())\n",
    "print(df['Severe'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct Preprocessing tasks on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnosis object\n",
      "ID object\n",
      "hospitalized_date datetime64[ns]\n",
      "Initial_CXR object\n",
      "Initial_CT object\n",
      "Initial_PCR_c object\n",
      "Initial_PCR_r object\n",
      "FU1_CXR object\n",
      "FU1_CT object\n",
      "FU1_PCR_c object\n",
      "FU1_PCR_r object\n",
      "FU2_CT object\n",
      "FU2_PCR_c object\n",
      "FU2_PCR_r object\n",
      "FU3_PR object\n",
      "FU3_CXR object\n",
      "FU3_CT object\n",
      "FU3_PCR_c object\n",
      "FU3_PCR_r object\n",
      "FU4_CXR object\n",
      "FU4_CT object\n",
      "FU4_PCR_c object\n",
      "FU4_PCR_r object\n",
      "Last_CXR object\n",
      "Last_CT object\n",
      "Last_PCR_c object\n",
      "Last_PCR_r object\n",
      "TX object\n",
      "O2sup object\n",
      "ECMO object\n",
      "ICU_date object\n",
      "Mild object\n",
      "Moderate object\n",
      "Severe object\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing of errors in the dataset\n",
    "changeCols = ['Initial_FIO2', 'FU1_FIO2', 'FU2_FIO2', \n",
    "              'FU3_FIO2', 'FU4_FIO2', 'Last_FIO2', 'FU2_LDH']\n",
    "for item in changeCols:\n",
    "    df[item] = pd.to_numeric(df[item], errors='coerce')\n",
    "\n",
    "#Checking whether objects are converted correctly: items in changeCols shouldn't be printed\n",
    "for cnt, v in enumerate(df.dtypes):\n",
    "    if v not in ['int64', 'float64']:\n",
    "        print(df.columns[cnt], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess PCR tests\n",
    "pcr_Cols = ['Initial_PCR_c', 'FU1_PCR_c', 'FU2_PCR_c', 'FU3_PCR_c', \n",
    "            'FU4_PCR_c', 'Last_PCR_c', 'Initial_PCR_r', 'FU1_PCR_r', \n",
    "            'FU2_PCR_r', 'FU3_PCR_r', 'FU4_PCR_r', 'Last_PCR_r']\n",
    "firstHalf = ['Initial_PCR_c', 'FU1_PCR_c', 'FU2_PCR_c', 'Initial_PCR_r', 'FU1_PCR_r', 'FU2_PCR_r'] \n",
    "secondHalf = ['FU3_PCR_c','FU4_PCR_c', 'Last_PCR_c', 'FU3_PCR_r', 'FU4_PCR_r', 'Last_PCR_r']\n",
    "#Create temporary dataframe\n",
    "df_temp = df.copy()\n",
    "df_temp = df_temp[pcr_Cols]\n",
    "\n",
    "#Turn PCR test less than 38 into positive higher than 38 into negative\n",
    "#Negative: 0, Positive: 1, Equivocal: 2\n",
    "for item in pcr_Cols:\n",
    "    for i in range (len(df_temp[item])): \n",
    "        #Turn str with numeric values into numeric data type\n",
    "        if type(df_temp[item].iloc[i]) == str and df_temp[item].iloc[i].isalpha() == False:\n",
    "            df_temp[item].iloc[i] = pd.to_numeric(df_temp[item].iloc[i], errors = 'ignore')\n",
    "\n",
    "        #Turn float or int values to Postiive or Negative depending on its CT values (cutoff: 40)\n",
    "        if df_temp[item].notnull and (type(df_temp[item].iloc[i]) == float or type(df_temp[item].iloc[i]) == np.float64 \n",
    "                  or type(df_temp[item].iloc[i]) == int\n",
    "                  or type(df_temp[item].iloc[i]) == np.int64):\n",
    "            if df_temp[item].iloc[i] >= 40:\n",
    "                df_temp[item].iloc[i] = 0\n",
    "            elif df_temp[item].iloc[i] < 40:\n",
    "                df_temp[item].iloc[i] = 1\n",
    "\n",
    "        #Fix the strange values and capitalize first letter, then convert to values\n",
    "        if type(df_temp[item].iloc[i]) == str:\n",
    "            #Capitalize the first letter\n",
    "            df_temp[item].iloc[i] = df_temp[item].iloc[i].capitalize()\n",
    "            if df_temp[item].iloc[i] == 'Negativeative' or df_temp[item].iloc[i] == 'Negative':\n",
    "                df_temp[item].iloc[i] = 0\n",
    "            if df_temp[item].iloc[i] == '29,26' or df_temp[item].iloc[i] == 'Positive':\n",
    "                df_temp[item].iloc[i] = 1\n",
    "            if df_temp[item].iloc[i] == '재확인' or df_temp[item].iloc[i] == 'Equivoca' or df_temp[item].iloc[i] == 'Equivocal':\n",
    "                df_temp[item].iloc[i] = 2\n",
    "        \n",
    "        #Equivocal은 Initial~FU2에 있으면 1(positive), FU3~last에 있으면 0(negative)\n",
    "        if df_temp[item].iloc[i] == 2 and item in str(firstHalf):\n",
    "            df_temp[item].iloc[i] = 1\n",
    "        elif df_temp[item].iloc[i] == 2 and item in str(secondHalf):\n",
    "            df_temp[item].iloc[i] = 0\n",
    "        \n",
    "    #Transfer to original dataframe from temp dataframe    \n",
    "    df[item] = df_temp[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinePCR(df, item, A, B):\n",
    "    df[item] = np.nan\n",
    "    for i in range (len(df)):\n",
    "        if df[A].notnull()[i] == True and df[B].notnull()[i] == True:\n",
    "            df[item].iloc[i] = '0'\n",
    "        if df[A].iloc[i] == 1 or df[B].iloc[i] == 1:\n",
    "            df[item].iloc[i] = '1'\n",
    "    return df\n",
    "\n",
    "df = combinePCR(df, 'Initial_PCR', 'Initial_PCR_c', 'Initial_PCR_r')\n",
    "df = combinePCR(df, 'FU1_PCR', 'FU1_PCR_c', 'FU1_PCR_r')\n",
    "df = combinePCR(df, 'FU2_PCR', 'FU2_PCR_c', 'FU2_PCR_r')\n",
    "df = combinePCR(df, 'FU3_PCR', 'FU3_PCR_c', 'FU3_PCR_r')\n",
    "df = combinePCR(df, 'FU4_PCR', 'FU4_PCR_c', 'FU4_PCR_r')\n",
    "df = combinePCR(df, 'Last_PCR', 'Last_PCR_c', 'Last_PCR_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    4460\n",
      "0     138\n",
      "Name: Initial_PCR, dtype: int64\n",
      "1    9061\n",
      "0     138\n",
      "Name: Initial_PCR, dtype: int64\n",
      "1    2279\n",
      "0     135\n",
      "Name: FU1_PCR, dtype: int64\n",
      "1    9064\n",
      "0     135\n",
      "Name: FU1_PCR, dtype: int64\n",
      "1    2832\n",
      "0     249\n",
      "Name: FU2_PCR, dtype: int64\n",
      "1    8950\n",
      "0     249\n",
      "Name: FU2_PCR, dtype: int64\n",
      "1    1976\n",
      "0     316\n",
      "Name: FU3_PCR, dtype: int64\n",
      "1    8883\n",
      "0     316\n",
      "Name: FU3_PCR, dtype: int64\n",
      "1    1311\n",
      "0     285\n",
      "Name: FU4_PCR, dtype: int64\n",
      "1    8914\n",
      "0     285\n",
      "Name: FU4_PCR, dtype: int64\n",
      "1    829\n",
      "0    514\n",
      "Name: Last_PCR, dtype: int64\n",
      "1    8685\n",
      "0     514\n",
      "Name: Last_PCR, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#After combining PCR, for missing PCR we impute Nan with 1 because our patient set is made up of COVID positive\n",
    "PCR_Names = ['Initial_PCR', 'FU1_PCR', 'FU2_PCR', 'FU3_PCR', 'FU4_PCR', 'Last_PCR' ]\n",
    "for item in PCR_Names:\n",
    "    print(df[item].value_counts())\n",
    "    df[item]=df[item].fillna('1')\n",
    "    print(df[item].value_counts())\n",
    "#Remove PCR columns because they become useless for this study\n",
    "df = df.drop(columns=pcr_Cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 3.0 6.0 5.0 10.0 2.0 0.0 1.0 7.0 4.0 8.0 12.0 11.0 14.0 9.0 -1.0 -4.0\n",
      " -6.0 19.0 15.0 34.0 41.0 60.0 47.0 13.0 -8.0 36.0 24.0 17.0 16.0 87.0\n",
      " 30.0 26 -11 -31 -2 38 -3 28 -15 -5 43 'Positive' -7 -16 42 -9 49 31 -12\n",
      " 39 -21 45.0 56.0 102.0 21 103 159 32 -19 -71 -10 20 ' ' 130] O2sup\n",
      "[ nan   6.   7.   8.   3.  10.   0.   1.   5.   9.   2.   4.  16.  21.\n",
      "  13.  -1.  25.  30.  53.  17.  14.  46.  12.  18. -12.  19.  11.  26.\n",
      "  50.  -2.  38.  -3.  -5.  20.  33.  42.  29.  32.  -6. 164. -11. -50.\n",
      "  41.  -8.  37. 130.  28.] ventilator\n",
      "[nan 6 10 3 1 13 'Positive' 5 16 18 7 2 30 14 8 12 17 19 4 9 81 26 15 21\n",
      " 31 107 20.0 46.0 42.0 0.0 23.0 11.0 -11.0 130.0 58.0] ECMO\n",
      "[nan 4 6 3 1 'Positive' 8 13 0 24 11.0 58.0 5.0 18.0 2.0 7.0 20.0 19.0\n",
      " 47.0 21.0 12.0 -1.0 9.0 10.0 15.0 38.0 39.0 26.0 50.0 -2.0 31.0 29.0 -4.0\n",
      " 36.0 35.0 16.0 -5.0 42.0 57.0 22.0 32.0 -13.0 25.0 28.0 -27.0 -7.0 45.0\n",
      " -3.0 -9.0 30.0 41.0 17.0 37.0 -10.0 -29.0 149.0] ICU_date\n",
      "[4 2 0 2.4 3 '3,4' 1 '2,4' '1,4' '1,2,4' '1,2' nan '2,3,4' '0' '1,3'] TX\n",
      "[ 0.  1. nan] UD_other\n"
     ]
    }
   ],
   "source": [
    "cols = ['O2sup', 'ventilator', 'ECMO', 'ICU_date', 'TX', 'UD_other']\n",
    "UD = ['UD_HT','UD_DM', 'UD_CVD', 'UD_cancer', 'UD_other']\n",
    "SMT = ['SMT_fever', 'SMT_cough', 'SMT_sputum', 'SMT_dyspnea', 'SMT_myalgia', 'SMT_mental', 'SMT_GI']\n",
    "CXRCT = ['Initial_CXR', 'FU1_CXR', 'FU2_CXR', 'FU3_CXR', 'FU4_CXR', 'Last_CXR', 'Initial_CT', 'FU1_CT', 'FU2_CT', 'FU3_CT', 'FU4_CT', 'Last_CT']\n",
    "\n",
    "for item in cols:\n",
    "    print(pd.unique(df[item]), item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 2.0 1.0 nan '1' '2' '0' 'Unknown'] Initial_CXR\n",
      "[1.0 0.0 2.0 nan '1' '2' '0' 'Unknown'] FU1_CXR\n",
      "[ 1.  0.  2. nan] FU2_CXR\n",
      "[1.0 0.0 2.0 nan '0' '2' '1' ' '] FU3_CXR\n",
      "[1.0 0.0 2.0 nan '0' '2' '1' ' ' 'Unknown'] FU4_CXR\n",
      "[nan 1.0 0.0 2.0 '2' '0' '1' ' '] Last_CXR\n",
      "[nan 1.0 2.0 0.0 '1' '0' '2' ' ' 'Unknown'] Initial_CT\n",
      "[nan 2.0 1.0 0.0 '1' '0' '2' ' ' 'Unknown'] FU1_CT\n",
      "[1.0 nan 2.0 0.0 '2' '1' ' ' '0' 'Unknown'] FU2_CT\n",
      "[nan 1.0 0.0 2.0 '1' ' ' '0' '2' 'Unknown'] FU3_CT\n",
      "[nan 1.0 0.0 2.0 '1' '2' ' ' '0' 'Unknown'] FU4_CT\n",
      "[nan 2.0 1.0 0.0 '2' '1' ' ' '0' 'Unknown'] Last_CT\n"
     ]
    }
   ],
   "source": [
    "#Preprocess Initial_CXR: turn 5 & loss to null\n",
    "for i in range(len(df['Initial_CXR'])):\n",
    "    if df['Initial_CXR'].iloc[i] == 5:\n",
    "        df['Initial_CXR'].iloc[i] = np.nan\n",
    "    if df['Initial_CXR'].iloc[i] == 'loss':\n",
    "        df['Initial_CXR'].iloc[i] = np.nan \n",
    "for item in CXRCT:\n",
    "    print(pd.unique(df[item]), item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>TX_0</th>\n",
       "      <th>TX_1</th>\n",
       "      <th>TX_2</th>\n",
       "      <th>TX_3</th>\n",
       "      <th>TX_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9194</th>\n",
       "      <td>224031</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9195</th>\n",
       "      <td>224032</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9196</th>\n",
       "      <td>224033</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9197</th>\n",
       "      <td>224034</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9198</th>\n",
       "      <td>224035</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9199 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          No  TX_0  TX_1  TX_2  TX_3  TX_4\n",
       "0     200001     0     0     0     0     1\n",
       "1     200002     0     0     1     0     0\n",
       "2     200003     0     0     0     0     1\n",
       "3     200004     0     0     1     0     0\n",
       "4     200005     0     0     1     0     0\n",
       "...      ...   ...   ...   ...   ...   ...\n",
       "9194  224031     0     1     0     0     1\n",
       "9195  224032     0     1     0     0     0\n",
       "9196  224033     0     1     0     0     0\n",
       "9197  224034     1     0     0     0     0\n",
       "9198  224035     0     1     0     0     1\n",
       "\n",
       "[9199 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One hot encoding for Treatment column \n",
    "df_OneHot = df.copy()\n",
    "df_OneHot['TX'] = df_OneHot['TX'].astype(str).replace('nan','0').apply(lambda x: x.split(','))\n",
    "df_OneHotLong = df_OneHot.explode('TX')\n",
    "df_OneHotTemp = pd.concat([df, pd.get_dummies(df_OneHotLong['TX'],prefix='TX', prefix_sep='_')], axis=1)\n",
    "df_OneHotDone = df_OneHotTemp.groupby('No').max().reset_index()\n",
    "TX_Cols = ['No','TX_0','TX_1','TX_2','TX_3','TX_4']\n",
    "TX_Cols_With_No = ['No','TX_0','TX_1','TX_2','TX_3','TX_4']\n",
    "df_OneHotDone[TX_Cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200001    1\n",
      "220972    1\n",
      "220966    1\n",
      "220967    1\n",
      "220968    1\n",
      "         ..\n",
      "211804    1\n",
      "211803    1\n",
      "211802    1\n",
      "211800    1\n",
      "224035    1\n",
      "Name: No, Length: 9199, dtype: int64\n",
      "0    6733\n",
      "1    2466\n",
      "Name: TX_0, dtype: int64\n",
      "0    7012\n",
      "1    2187\n",
      "Name: TX_1, dtype: int64\n",
      "0    8582\n",
      "1     617\n",
      "Name: TX_2, dtype: int64\n",
      "0    9007\n",
      "1     192\n",
      "Name: TX_3, dtype: int64\n",
      "1    4820\n",
      "0    4379\n",
      "Name: TX_4, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Merge original dataframe and one-hot-encoded dataframe, then remove original TX column\n",
    "df = pd.merge(df,df_OneHotDone[TX_Cols_With_No], on='No',how='left').drop(columns='TX')\n",
    "\n",
    "#Print results\n",
    "for item in TX_Cols:\n",
    "    print(df[item].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding for Smoking column\n",
    "df_Smoking = pd.get_dummies(df['smoking']).rename(columns={0.0: \"Smoking_0\", 1.0: \"Smoking_1\", 2.0: \"Smoking_2\", 3.0: \"Smoking_3\"})\n",
    "\n",
    "#Merge original dataframe and one-hot-encoded dataframe, then remove original TX column\n",
    "df = df.join(df_Smoking).drop(columns='smoking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ALC, ANC, WBC data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BloodCell = [['Initial_WBC', 'Initial_ANC', 'Initial_ALC'],\n",
    "             ['FU1_WBC', 'FU1_ANC', 'FU1_ALC'],\n",
    "             ['FU2_WBC', 'FU2_ANC', 'FU2_ALC']]\n",
    "df_bloodcell = df[['No', 'ID', 'age', 'sex', 'dx_date', \n",
    "              'Initial_WBC', 'Initial_ANC', 'Initial_ALC', \n",
    "              'FU1_WBC', 'FU1_ANC', 'FU1_ALC',\n",
    "              'FU2_WBC', 'FU2_ANC', 'FU2_ALC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_bloodcell)):\n",
    "    for WBC, ANC, ALC in BloodCell:\n",
    "        sumVal = np.NaN\n",
    "        WN_Val = np.NaN\n",
    "        WL_Val = np.NaN\n",
    "        ANC_val = df_bloodcell[ANC][i]\n",
    "        ALC_val = df_bloodcell[ALC][i]\n",
    "        WBC_val = df_bloodcell[WBC][i]\n",
    "        #Assign sumval by checking if ANC & ALC column is empty or not\n",
    "        if pd.notnull(ANC_val) and pd.notnull(ALC_val):\n",
    "            sumVal = round(ANC_val + ALC_val,1)\n",
    "        elif pd.notnull(WBC_val) and pd.notnull(ALC_val):\n",
    "            WL_Val = WBC_val - ALC_val\n",
    "        elif pd.notnull(WBC_val) and pd.notnull(ANC_val):\n",
    "            WN_Val = WBC_val - ANC_val\n",
    "        elif pd.isnull(ANC_val):\n",
    "            sumVal = round(ALC_val,1)\n",
    "        elif pd.isnull(ALC_val):\n",
    "            sumVal = round(ANC_val,1)\n",
    "        \n",
    "        #WBC val less than SumVal then sumval = WBC val\n",
    "        if WBC_val < sumVal:\n",
    "            df_bloodcell[WBC][i] = sumVal\n",
    "\n",
    "        #ANC val missing then fill in with WBC - ALC\n",
    "        if pd.notnull(WBC_val) and pd.notnull(ALC_val) and pd.isnull(ANC_val):\n",
    "            df_bloodcell[ANC][i] = WL_Val\n",
    "\n",
    "        #ALC val missing then fill in with WBC - ANC\n",
    "        if pd.notnull(WBC_val) and pd.notnull(ANC_val) and pd.isnull(ALC_val):\n",
    "            df_bloodcell[ALC][i] = WN_Val  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract only hospital ID from ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def search_ID(ID):\n",
    "    return re.match(r'^[A-Za-z]{3}', ID)[0]\n",
    "df['ID'] = df['ID'].apply(lambda x: search_ID(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save datset as new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save preprocessed data file as CRF file\n",
    "df.to_csv(\"../Data/Preprocessed/CRF_Preprocessed_Original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
